{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labolatorium 3 - Kompresja tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from string import printable\n",
    "from random import choice\n",
    "from bitarray import bitarray\n",
    "from os.path import getsize\n",
    "from os import remove\n",
    "from time import time\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane tekstowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open (\"krzyzacy.txt\", 'r')\n",
    "guttenberg = f.read ()\n",
    "f.close ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutt_1kB = guttenberg[:1024]\n",
    "gutt_10kB = guttenberg[:10240]\n",
    "gutt_100kB = guttenberg[:102400]\n",
    "gutt_1MB = guttenberg[:1024*1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open (\"git.txt\", 'r')\n",
    "github = f.read ()\n",
    "f.close ()\n",
    "github *= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "git_1kB = github[:1024]\n",
    "git_10kB = github[:10240]\n",
    "git_100kB = github[:102400]\n",
    "git_1MB = github[:1024*1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text (n):\n",
    "    result = \"\"\n",
    "    for _ in range (n):\n",
    "        letter = choice(printable)\n",
    "        result += letter\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_1kB = make_text(1024)\n",
    "rand_10kB = make_text(10240)\n",
    "rand_100kB = make_text(102400)\n",
    "rand_1MB = make_text(1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struktura węzła"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__ (self, weight = 0, val = None):\n",
    "        self.value = val\n",
    "        self.weight = weight        \n",
    "        self.parent = self\n",
    "        self.children = {}\n",
    "        \n",
    "    def make_parent (self, n1, n2):\n",
    "        self.children[1] = n1\n",
    "        self.children[0] = n2\n",
    "        self.weight = n1.weight + n2.weight\n",
    "        n1.parent = self\n",
    "        n2.parent = self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statystyczny Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_letter (text):\n",
    "    count = defaultdict(int)\n",
    "    for letter in text:\n",
    "        count[letter] += 1\n",
    "    return count\n",
    "\n",
    "def huffman (text):\n",
    "    letter_counts = count_letter (text)\n",
    "    nodes = []\n",
    "    for letter, weight in letter_counts.items():\n",
    "        nodes.append(Node(weight, letter))\n",
    "    internal_nodes = []\n",
    "    leafs = sorted(nodes, key=lambda n: n.weight)\n",
    "    while len(leafs) + len(internal_nodes) > 1:\n",
    "        elements = []\n",
    "        for _ in range (2):\n",
    "            if len(leafs) == 0:\n",
    "                elements.append(internal_nodes[0])\n",
    "                del (internal_nodes[0])\n",
    "            elif len (internal_nodes) == 0 or leafs[0].weight <= internal_nodes[0].weight:\n",
    "                elements.append(leafs[0])\n",
    "                del (leafs[0])\n",
    "            else:\n",
    "                elements.append(internal_nodes[0])\n",
    "                del (internal_nodes[0])\n",
    "        new = Node()\n",
    "        new.make_parent(elements[0], elements[1])\n",
    "        internal_nodes.append(new)\n",
    "    return internal_nodes[0]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamiczny Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_node (root, w):\n",
    "    node = root\n",
    "    qu = Queue ()\n",
    "    qu.put(node)\n",
    "    while not qu.empty():\n",
    "        node = qu.get()\n",
    "        if node.weight == w:\n",
    "            return node\n",
    "        if node.value == None:\n",
    "            qu.put(node.children[1])\n",
    "            qu.put(node.children[0])\n",
    "    return None\n",
    "\n",
    "def increment (node, root):\n",
    "    if node == root:\n",
    "        node.weight += 1\n",
    "        return\n",
    "    w = node.weight\n",
    "    w_node = find_node (root, w)\n",
    "    if w_node != node and w_node != node.parent:\n",
    "        parent = node.parent\n",
    "        w_parent = w_node.parent\n",
    "        if parent.children[0] == node:\n",
    "            parent.children[0] = w_node\n",
    "        else:\n",
    "            parent.children[1] = w_node\n",
    "        if w_parent.children[0] == w_node:\n",
    "            w_parent.children[0] = node\n",
    "        else:\n",
    "            w_parent.children[1] = node\n",
    "        w_node.parent = parent\n",
    "        node.parent = w_parent\n",
    "    node.weight += 1\n",
    "    increment (node.parent, root)\n",
    "        \n",
    "def dynamic_huffman (text):\n",
    "    nodes = {}\n",
    "    nodes[\"##\"] = Node (val = \"##\")\n",
    "    root = nodes[\"##\"]\n",
    "    for letter in text:\n",
    "        if letter in nodes:\n",
    "            node = nodes[letter]\n",
    "            increment(node, root)\n",
    "        else:\n",
    "            updated_node = nodes[\"##\"]\n",
    "            updated_node.value = None\n",
    "            node = Node(val = letter)\n",
    "            del nodes[\"##\"]\n",
    "            zero_node = Node(val = \"##\")\n",
    "            updated_node.make_parent (node, zero_node)\n",
    "            node.weight = 1\n",
    "            nodes[letter] = node\n",
    "            nodes[\"##\"] = zero_node\n",
    "            increment(updated_node, root)\n",
    "    return root    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje kodujące i dekodujące tekst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Struktura pliku wygląda następująco: najpierw pojawiają się zera które ewentualnie byłyby wstawione na koniec pliku aby liczba bitów była podzielna przez 8, następnie jedynka i po tym słownik postaci: 32 bity (UTF-16) na literkę/znak, 8 bitów na ilość bitów w kodzie huffmana, kod huffmana itd., koniec słownika rozpoznajemy po tym że kod literki to \"0\"*32 bo jest to znak NULL. Po tym kodzie następuje zakodowany tekst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def library_from_huffman (node, lib, key = \"\"):\n",
    "    if node.value != None:\n",
    "        #print (node.value, \"->\", key)\n",
    "        if node.value == \"##\": return\n",
    "        lib[node.value] = key\n",
    "    else:\n",
    "        library_from_huffman (node.children[0], lib, key + \"0\")\n",
    "        library_from_huffman (node.children[1], lib, key + \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode (text, typ = 1, tree = None):\n",
    "    if tree == None:\n",
    "        if typ:\n",
    "            tree = huffman(text)\n",
    "        else:\n",
    "            tree = dynamic_huffman (text)\n",
    "    library = {}\n",
    "    library_from_huffman(tree, library)\n",
    "    #kodowanie tekstu\n",
    "    encode_text = bitarray()\n",
    "    for letter in text:\n",
    "        encode_text += bitarray(library[letter])\n",
    "    #kodowanie słownika\n",
    "    encode_library = bitarray(\"1\")\n",
    "    for letter, code in library.items():\n",
    "        k = len (code)\n",
    "        kb = bin(k)[2:]\n",
    "        t = 8 - len (kb)\n",
    "        kb = \"0\"*t + kb\n",
    "        encode_library.frombytes(bytes(letter, \"utf-16\"))\n",
    "        encode_library += bitarray(kb)\n",
    "        encode_library += bitarray(code)\n",
    "    encode_library += bitarray(\"0\"*32)\n",
    "    \n",
    "    k = 8 - ((len(encode_library) + len(encode_text)) % 8)\n",
    "    if k == 8: k = 0\n",
    "    result = bitarray(\"0\"*k) + encode_library + encode_text\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_tree (tree, letter, code): #budowanie drzewa do dekodowania tekstu\n",
    "    node = tree\n",
    "    for bit in code:\n",
    "        if bit:\n",
    "            if 1 not in node.children:\n",
    "                node.children[1] = Node ()\n",
    "                node.children[1].parent = node\n",
    "            node = node.children[1]\n",
    "        else:\n",
    "            if 0 not in node.children:\n",
    "                node.children[0] = Node ()\n",
    "                node.children[0].parent = node\n",
    "            node = node.children[0]\n",
    "    node.value = letter\n",
    "\n",
    "def decode (code):\n",
    "    tree = Node()\n",
    "    #odczyt początkowych zer które ignorujemy\n",
    "    i = 0\n",
    "    while not code[i]: i+=1\n",
    "    i+=1\n",
    "    #odczyt alfabetu dopóki znajdziemy letter = '0'*8\n",
    "    #w trakcie odczytu budowa drzewa\n",
    "    q = 32\n",
    "    letter = code[i:i+q]\n",
    "    i+=q\n",
    "    while letter != bitarray(\"0\"*q):\n",
    "        letter = letter.tobytes().decode(\"utf-16\")\n",
    "        kb = code[i:i+8]\n",
    "        kbb = \"\"\n",
    "        for bit in kb:\n",
    "            if bit:\n",
    "                kbb += \"1\"\n",
    "            else:\n",
    "                kbb += \"0\"\n",
    "        k = int (kbb, 2)\n",
    "        i+=8\n",
    "        cd = code[i:i+k]\n",
    "        i+=k\n",
    "        add_to_tree (tree, letter, cd)\n",
    "        letter = code[i:i+q]\n",
    "        i+=q\n",
    "    #dekodowanie wykorzystując drzewo\n",
    "    result = \"\"\n",
    "    node = tree\n",
    "    for bit in code[i:]:\n",
    "        if bit:\n",
    "            node = node.children[1]\n",
    "        else:\n",
    "            node = node.children[0]\n",
    "        if node.value != None:\n",
    "            result += node.value\n",
    "            node = tree\n",
    "    return result            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapis i odczyt z pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file (text, filepath = \"tmp.txt\"):\n",
    "    f = open (filepath, 'wb')\n",
    "    f.write(text.tobytes())\n",
    "    f.close()\n",
    "    \n",
    "def read_from_file (filepath = \"tmp.txt\"):\n",
    "    f = open (filepath, 'rb')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    result = bitarray ()\n",
    "    result.frombytes(text)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pomiar czasu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time (function, *data):\n",
    "    start_time = time()\n",
    "    res = function (*data)\n",
    "    end_time = time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return elapsed_time, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test jednostkowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compression (text):\n",
    "    f = open (\"temporary.txt\", 'w')\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "    size = getsize(\"temporary.txt\")\n",
    "    remove (\"temporary.txt\")\n",
    "    time_encode, code = measure_time (encode, text, 1)\n",
    "    time_stat = time_encode\n",
    "    write_to_file (code)\n",
    "    new_size = getsize (\"tmp.txt\")\n",
    "    new_code = read_from_file ()\n",
    "    remove (\"tmp.txt\")\n",
    "    time_decode, result = measure_time (decode, new_code)\n",
    "    print (\"Test kompresji tekstu dla pliku o rozmiarze\", size, \"Bajtów i statystycznego drzewa Huffmana\")\n",
    "    print (\"Rozmiar pliku po kompresji wyniósł\", new_size, \"Bajtów\")\n",
    "    print (\"Współczynnik kompresji wynosi\", (1-new_size/size)*100)\n",
    "    print (\"Czas kompresji wyniósł\", time_encode, \"natomiast czas dekompresji\", time_decode)\n",
    "    if result == text:\n",
    "        print (\"Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\")\n",
    "    else:\n",
    "        print (\"Utrata tekstu\")\n",
    "    print ()\n",
    "    time_encode, code = measure_time (encode, text, 0)\n",
    "    time_dyn = time_encode\n",
    "    write_to_file (code)\n",
    "    new_size = getsize (\"tmp.txt\")\n",
    "    new_code = read_from_file ()\n",
    "    remove (\"tmp.txt\")\n",
    "    time_decode, result = measure_time (decode, new_code)\n",
    "    print (\"Test kompresji tekstu dla pliku o rozmiarze\", size, \"Bajtów i dynamicznego drzewa Huffmana\")\n",
    "    print (\"Rozmiar pliku po kompresji wyniósł\", new_size, \"Bajtów\")\n",
    "    print (\"Współczynnik kompresji wynosi\", (1-new_size/size)*100)\n",
    "    print (\"Czas kompresji wyniósł\", time_encode, \"natomiast czas dekompresji\", time_decode)\n",
    "    if result == text:\n",
    "        print (\"Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\")\n",
    "    else:\n",
    "        print (\"Utrata tekstu\")\n",
    "    print ()\n",
    "    print (\"Czas kodowania dla algorytmu statystycznego wynosi\", time_stat, \"natomiast dla dynamicznego\", time_dyn)\n",
    "    print (\"Algorytm statystyczny jest\", time_dyn/time_stat, \"razy szybszy od dynamicznego\")\n",
    "    print ()\n",
    "    print (\"*****************************************************************\")\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test kompresji tekstu dla pliku o rozmiarze 11 Bajtów i statystycznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 34 Bajtów\n",
      "Współczynnik kompresji wynosi -209.0909090909091\n",
      "Czas kompresji wyniósł 7.867813110351562e-05 natomiast czas dekompresji 6.532669067382812e-05\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 11 Bajtów i dynamicznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 34 Bajtów\n",
      "Współczynnik kompresji wynosi -209.0909090909091\n",
      "Czas kompresji wyniósł 0.0009222030639648438 natomiast czas dekompresji 5.841255187988281e-05\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Czas kodowania dla algorytmu statystycznego wynosi 7.867813110351562e-05 natomiast dla dynamicznego 0.0009222030639648438\n",
      "Algorytm statystyczny jest 11.72121212121212 razy szybszy od dynamicznego\n",
      "\n",
      "*****************************************************************\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 2097152 Bajtów i statystycznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 262159 Bajtów\n",
      "Współczynnik kompresji wynosi 87.4992847442627\n",
      "Czas kompresji wyniósł 0.5689935684204102 natomiast czas dekompresji 0.37628626823425293\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 2097152 Bajtów i dynamicznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 393231 Bajtów\n",
      "Współczynnik kompresji wynosi 81.2492847442627\n",
      "Czas kompresji wyniósł 58.642913818359375 natomiast czas dekompresji 0.53859543800354\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Czas kodowania dla algorytmu statystycznego wynosi 0.5689935684204102 natomiast dla dynamicznego 58.642913818359375\n",
      "Algorytm statystyczny jest 103.0642823980571 razy szybszy od dynamicznego\n",
      "\n",
      "*****************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_compression(\"abracadabra\")\n",
    "string = \"ab\" *1024 *1024\n",
    "test_compression(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test kompresji tekstu dla pliku o rozmiarze 1024 Bajtów i statystycznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 1073 Bajtów\n",
      "Współczynnik kompresji wynosi -4.78515625\n",
      "Czas kompresji wyniósł 0.0009694099426269531 natomiast czas dekompresji 0.001154184341430664\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 1024 Bajtów i dynamicznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 1074 Bajtów\n",
      "Współczynnik kompresji wynosi -4.8828125\n",
      "Czas kompresji wyniósł 0.5927977561950684 natomiast czas dekompresji 0.0010905265808105469\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Czas kodowania dla algorytmu statystycznego wynosi 0.0009694099426269531 natomiast dla dynamicznego 0.5927977561950684\n",
      "Algorytm statystyczny jest 611.5036891293655 razy szybszy od dynamicznego\n",
      "\n",
      "*****************************************************************\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 10240 Bajtów i statystycznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 6436 Bajtów\n",
      "Współczynnik kompresji wynosi 37.1484375\n",
      "Czas kompresji wyniósł 0.004329681396484375 natomiast czas dekompresji 0.007886409759521484\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 10240 Bajtów i dynamicznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 6438 Bajtów\n",
      "Współczynnik kompresji wynosi 37.12890625000001\n",
      "Czas kompresji wyniósł 4.363410949707031 natomiast czas dekompresji 0.008259296417236328\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Czas kodowania dla algorytmu statystycznego wynosi 0.004329681396484375 natomiast dla dynamicznego 4.363410949707031\n",
      "Algorytm statystyczny jest 1007.790308370044 razy szybszy od dynamicznego\n",
      "\n",
      "*****************************************************************\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 102402 Bajtów i statystycznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 58891 Bajtów\n",
      "Współczynnik kompresji wynosi 42.49038104724517\n",
      "Czas kompresji wyniósł 0.04249882698059082 natomiast czas dekompresji 0.07039070129394531\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 102402 Bajtów i dynamicznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 58891 Bajtów\n",
      "Współczynnik kompresji wynosi 42.49038104724517\n",
      "Czas kompresji wyniósł 38.89326882362366 natomiast czas dekompresji 0.06696105003356934\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n",
      "Czas kodowania dla algorytmu statystycznego wynosi 0.04249882698059082 natomiast dla dynamicznego 38.89326882362366\n",
      "Algorytm statystyczny jest 915.1609958878672 razy szybszy od dynamicznego\n",
      "\n",
      "*****************************************************************\n",
      "\n",
      "Test kompresji tekstu dla pliku o rozmiarze 1048626 Bajtów i statystycznego drzewa Huffmana\n",
      "Rozmiar pliku po kompresji wyniósł 595577 Bajtów\n",
      "Współczynnik kompresji wynosi 43.20405940726245\n",
      "Czas kompresji wyniósł 0.4348783493041992 natomiast czas dekompresji 0.7062227725982666\n",
      "Odczyt powiódł się, tekst otrzymany jest równy wyjściowemu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_compression(gutt_1kB)\n",
    "test_compression(gutt_10kB)\n",
    "test_compression(gutt_100kB)\n",
    "test_compression(gutt_1MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compression(git_1kB)\n",
    "test_compression(git_10kB)\n",
    "test_compression(git_100kB)\n",
    "test_compression(git_1MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_compression(rand_1kB)\n",
    "test_compression(rand_10kB)\n",
    "test_compression(rand_100kB)\n",
    "test_compression(rand_1MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wnioski:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Dla krótkich plików tekst skompesowany zajmuje więcej miejsca niż nieskompresowany, wynika to z potrzeby zapisu słownika."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Najlepsze efekty kompresji uzyskujemy dla tekstu pochodzącego z portalu guttenberg, ponieważ jest to tekst języka naturalnego, więc rozkład znaków nie jest jednostajny i używane są tylko litery i nieliczne symbole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Dla tekstu z rozkładu jednostajnego kompresja jest niewielka, jednakże występuje z faktu nie używania wszystkich możliwych znaków."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Dla tekstu składającego się tylko z liter 'a' i 'b' kompresja sięga 87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Statystyczny Huffman jest wielokrotnie szybszy od dynamicznego, wynika to użycia czasochłonnego BFSa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Współczynnik kompresji jest podobny dla obydwu algorytmów"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
